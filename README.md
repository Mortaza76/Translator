# ğŸ™ï¸ Urdu Speech Translation App

A modern, real-time speech translation application that translates Urdu speech to multiple languages and supports bidirectional conversation translation. Built with FastAPI backend and React frontend.

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![React](https://img.shields.io/badge/React-18.2-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

## ğŸ“‹ Table of Contents

- [Features](#features)
- [Architecture](#architecture)
- [Screenshots](#screenshots)
- [Installation](#installation)
- [Usage](#usage)
- [Workflow](#workflow)
- [API Documentation](#api-documentation)
- [Technical Details](#technical-details)
- [Examples](#examples)
- [Troubleshooting](#troubleshooting)

## âœ¨ Features

### ğŸ¯ Core Capabilities

- **ğŸ¤ Browser-Based Recording**: Record audio directly in your browser - no external software needed
- **ğŸŒ Multi-Language Support**: Translate to 10+ languages including English, French, Spanish, German, Italian, Portuguese, Japanese, Korean, Chinese, Arabic, and Hindi
- **ğŸ”„ Two-Way Translation**: 
  - **Single Mode**: Urdu â†’ Target Language
  - **Conversation Mode**: Bidirectional translation (Urdu â†” Target Language)
- **âš¡ Real-Time Processing**: See status updates as your audio is processed
- **ğŸ”Š Audio Playback**: Listen to translated speech instantly
- **ğŸ“ Conversation History**: Save and review all conversation exchanges
- **ğŸ¨ Modern UI**: Clean, minimal, and responsive design

### ğŸš€ Advanced Features

- **Fine-Tuned Urdu Model**: Uses `whisper-small-urdu` for superior Urdu transcription accuracy
- **GPU Acceleration**: Leverages Apple Silicon (MPS) for faster processing
- **Multi-Language Transcription**: Supports transcription in multiple languages (not just Urdu)
- **Automatic Speaker Switching**: In conversation mode, automatically switches between speakers
- **Audio Format Conversion**: Automatically converts WebM to WAV for processing

## ğŸ—ï¸ Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend (React)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Browser Audio Recording (MediaRecorder API)     â”‚   â”‚
â”‚  â”‚  WebM â†’ WAV Conversion                            â”‚   â”‚
â”‚  â”‚  Base64 Encoding                                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                        â†“                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  UI Components                                   â”‚   â”‚
â”‚  â”‚  - Mode Toggle (Single/Conversation)            â”‚   â”‚
â”‚  â”‚  - Language Selector                             â”‚   â”‚
â”‚  â”‚  - Recording Controls                            â”‚   â”‚
â”‚  â”‚  - Conversation History                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“ HTTP/REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Backend (FastAPI)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Step 1: Speech-to-Text                         â”‚   â”‚
â”‚  â”‚  - Urdu: whisper-small-urdu (fine-tuned)        â”‚   â”‚
â”‚  â”‚  - Others: whisper-small (multilingual)          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                        â†“                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Step 2: Translation                            â”‚   â”‚
â”‚  â”‚  - TranslateGemma:4b via Ollama                â”‚   â”‚
â”‚  â”‚  - Supports bidirectional translation           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                        â†“                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Step 3: Text-to-Speech                         â”‚   â”‚
â”‚  â”‚  - Piper TTS (local, fast)                      â”‚   â”‚
â”‚  â”‚  - Language-specific voices                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

**Backend:**
- **FastAPI**: Modern, fast web framework for building APIs
- **Whisper**: OpenAI's speech recognition (fine-tuned for Urdu)
- **TranslateGemma**: Ollama-based translation model
- **Piper TTS**: Fast, local neural text-to-speech
- **PyTorch**: Deep learning framework (with MPS support)

**Frontend:**
- **React 18**: Modern UI library
- **Vite**: Fast build tool and dev server
- **Axios**: HTTP client for API calls
- **Lucide React**: Beautiful icon library

## ğŸ“¸ Screenshots

### Main Interface

![Main UI](screenshots/Screenshot%202026-01-21%20at%204.55.01%20PM.png)
*Clean, modern interface with mode toggle and language selector*

### Single Translation Mode

![Single Mode](screenshots/Screenshot%202026-01-21%20at%204.55.01%20PM.png)
*Translate Urdu speech to any target language*

### Conversation Mode

![Conversation Mode](screenshots/Screenshot%202026-01-21%20at%204.47.06%20PM.png)
*Two-way translation with speaker indicators*

### Conversation History

![History](screenshots/conversation-history.png)
*View and replay all conversation exchanges*

**What to capture**: Conversation history panel showing multiple exchanges with source text, translations, and play buttons.

### Processing Status

![Processing](screenshots/processing.png)
*Real-time status updates during processing*

**What to capture**: Status message showing "Processing..." or "Transcribing..." with loading indicator.

### Example Translation Output

![Example Output](screenshots/example-output.png)
*Example: Urdu "Ø¢Ù¾ Ú©ÛŒØ³Û’ ÛÛŒÚºØŸ" â†’ English "How are you?"*

**What to capture**: A successful translation showing both Urdu text and translated text side by side.

## ğŸš€ Installation

### Prerequisites

- **Python 3.8+**
- **Node.js 18+** and npm
- **Ollama** with `translategemma:4b` model installed

### Step 1: Install Ollama

```bash
# Install Ollama (if not already installed)
# Visit: https://ollama.ai

# Pull the translation model
ollama pull translategemma:4b
```

### Step 2: Install Backend Dependencies

```bash
cd Text_to_Speech
pip install -r requirements.txt
```

### Step 3: Install Frontend Dependencies

```bash
cd frontend
npm install
cd ..
```

## ğŸ’» Usage

### Quick Start

**Option 1: Use the startup script**
```bash
./start_ui.sh
```

**Option 2: Manual start**

Terminal 1 - Backend:
```bash
python api_server.py
```

Terminal 2 - Frontend:
```bash
cd frontend
npm run dev
```

Then open `http://localhost:3000` in your browser.

### Single Translation Mode

1. Select target language from dropdown
2. Click "Start Recording"
3. Speak in Urdu
4. Click "Stop Recording"
5. View transcribed Urdu text and translation
6. Click "Play Translation" to hear the audio

### Conversation Mode

1. Click "Conversation Mode" toggle
2. Select target language (e.g., French)
3. **Person A**: Click "Start Recording" â†’ Speak Urdu â†’ Stop
4. System automatically translates and plays French audio
5. **Person B**: Click "Start Recording" â†’ Speak French â†’ Stop
6. System automatically translates and plays Urdu audio
7. Continue conversation back and forth
8. View full conversation history below

## ğŸ”„ Workflow

### Single Mode Workflow

```
User Records Urdu Audio
         â†“
Browser: WebM â†’ WAV Conversion
         â†“
Base64 Encoding
         â†“
POST /api/process-base64
         â†“
Backend: Transcribe Urdu (Whisper)
         â†“
Backend: Translate Urdu â†’ Target (TranslateGemma)
         â†“
Backend: TTS in Target Language (Piper)
         â†“
Return: Urdu Text + Translation + Audio
         â†“
Frontend: Display Results + Play Audio
```

### Conversation Mode Workflow

```
Person A Records Urdu
         â†“
Transcribe Urdu â†’ Translate to French â†’ TTS French
         â†“
Auto-play French Audio â†’ Switch to Person B
         â†“
Person B Records French
         â†“
Transcribe French â†’ Translate to Urdu â†’ TTS Urdu
         â†“
Auto-play Urdu Audio â†’ Switch to Person A
         â†“
Repeat...
```

## ğŸ“¡ API Documentation

### Endpoints

#### `GET /api/health`
Health check endpoint.

**Response:**
```json
{
  "status": "healthy"
}
```

#### `GET /api/languages`
Get list of supported languages.

**Response:**
```json
{
  "languages": [
    {"code": "en", "name": "English"},
    {"code": "fr", "name": "French"},
    ...
  ]
}
```

#### `POST /api/process-base64`
Process audio in single mode (Urdu â†’ Target).

**Request:**
```json
{
  "audio_data": "data:audio/wav;base64,...",
  "target_language": "English"
}
```

**Response:**
```json
{
  "status": "success",
  "urdu_text": "Ø¢Ù¾ Ú©ÛŒØ³Û’ ÛÛŒÚºØŸ",
  "translated_text": "How are you?",
  "audio_base64": "data:audio/wav;base64,..."
}
```

#### `POST /api/conversation`
Process audio in conversation mode (bidirectional).

**Request:**
```json
{
  "audio_data": "data:audio/wav;base64,...",
  "source_language": "Urdu",
  "target_language": "French",
  "conversation_mode": true
}
```

**Response:**
```json
{
  "status": "success",
  "source_text": "Ø¢Ù¾ Ú©Ø§ Ù†Ø§Ù… Ú©ÛŒØ§ ÛÛ’ØŸ",
  "source_language": "Urdu",
  "translated_text": "Comment vous appelez-vous?",
  "target_language": "French",
  "audio_base64": "data:audio/wav;base64,..."
}
```

## ğŸ”§ Technical Details

### Speech-to-Text

- **Urdu**: Uses fine-tuned `khawajaaliarshad/whisper-small-urdu` model
- **Other Languages**: Uses standard `openai/whisper-small` multilingual model
- **GPU Acceleration**: Apple Silicon MPS (Metal Performance Shaders)
- **Sample Rate**: 16 kHz (resampled from 48 kHz browser recording)

### Translation

- **Model**: TranslateGemma:4b via Ollama
- **Supports**: 100+ languages
- **Bidirectional**: Can translate between any two supported languages
- **Format**: Professional translator prompt format for accuracy

### Text-to-Speech

- **Engine**: Piper TTS (local, fast)
- **Voices**: Language-specific voices (e.g., `en_US-lessac-medium` for English)
- **Format**: 16-bit PCM WAV
- **Sample Rate**: Model-dependent (typically 22 kHz)

### Audio Processing

- **Browser Recording**: MediaRecorder API (WebM format)
- **Conversion**: Web Audio API converts WebM â†’ WAV
- **Encoding**: Base64 for API transmission
- **Processing**: DC offset removal, high-pass filtering, normalization

## ğŸ“ Examples

### Example 1: Simple Translation

**Input (Urdu Speech):**
> "Ø¢Ù¾ Ú©ÛŒØ³Û’ ÛÛŒÚºØŸ"

**Output (English):**
> "How are you?"

**Audio**: Plays English TTS

**Screenshot**: `screenshots/example-simple.png`

---

### Example 2: Conversation Exchange

**Person A (Urdu):**
> "Ù…ÛŒØ±Ø§ Ù†Ø§Ù… Ø§Ø­Ù…Ø¯ ÛÛ’"

**Translation (French):**
> "Mon nom est Ahmed"

**Person B (French):**
> "EnchantÃ©, Ahmed"

**Translation (Urdu):**
> "Ø®ÙˆØ´ÛŒ ÛÙˆØ¦ÛŒØŒ Ø§Ø­Ù…Ø¯"

**Screenshot**: `screenshots/example-conversation.png`

---

### Example 3: Complex Sentence

**Input (Urdu):**
> "Ø¬Ø¨ ØªÚ© Ù…ÛŒÚº Ù†Û’ ÛŒÛ Ú©Ø§Ù… Ù…Ú©Ù…Ù„ Ù†ÛÛŒÚº Ú©ÛŒØ§ØŒ Ù…ÛŒÚº Ù†ÛÛŒÚº Ø³Ùˆ Ø³Ú©ØªØ§"

**Output (English):**
> "Until I complete this work, I cannot sleep"

**Screenshot**: `screenshots/example-complex.png`

---

### Example 4: Multiple Languages

**Urdu â†’ Spanish:**
- Input: "Ø´Ú©Ø±ÛŒÛ"
- Output: "Gracias"

**Urdu â†’ German:**
- Input: "Ø¢Ù¾ Ú©ÛØ§Úº Ø±ÛØªÛ’ ÛÛŒÚºØŸ"
- Output: "Wo wohnen Sie?"

**Screenshot**: `screenshots/example-multilang.png`

## ğŸ› Troubleshooting

### Backend Issues

**Problem**: API server won't start
- **Solution**: Check if port 8000 is available: `lsof -ti:8000`
- **Solution**: Ensure all dependencies installed: `pip install -r requirements.txt`

**Problem**: Translation fails
- **Solution**: Verify Ollama is running: `ollama serve`
- **Solution**: Check model is installed: `ollama list`
- **Solution**: Pull model if missing: `ollama pull translategemma:4b`

**Problem**: Transcription is slow
- **Solution**: First run loads models (slow), subsequent runs faster
- **Solution**: Ensure GPU acceleration enabled (MPS on Apple Silicon)

### Frontend Issues

**Problem**: Microphone not working
- **Solution**: Use HTTPS or localhost (required for microphone access)
- **Solution**: Check browser permissions for microphone
- **Solution**: Try different browser (Chrome recommended)

**Problem**: CORS errors
- **Solution**: Backend CORS configured for `localhost:3000`
- **Solution**: Ensure backend running on port 8000

**Problem**: Audio playback fails
- **Solution**: Check browser audio permissions
- **Solution**: Verify audio format is supported

### Model Issues

**Problem**: Urdu transcription inaccurate
- **Solution**: Ensure using fine-tuned model (`whisper-small-urdu`)
- **Solution**: Speak clearly and reduce background noise
- **Solution**: Check audio quality (48 kHz recording recommended)

**Problem**: Translation quality poor
- **Solution**: Ensure TranslateGemma model is latest version
- **Solution**: Check source language is correctly identified
- **Solution**: For complex sentences, break into shorter phrases

## ğŸ“Š Performance

- **Transcription**: ~2-5 seconds (depending on audio length)
- **Translation**: ~3-8 seconds (depending on text length)
- **TTS**: ~1-3 seconds (depending on text length)
- **Total Pipeline**: ~6-16 seconds per translation

*Note: First run is slower due to model loading. Subsequent runs are faster.*

## ğŸ¯ Supported Languages

### Transcription Support
- Urdu (fine-tuned model)
- English, French, Spanish, German, Italian, Portuguese
- Japanese, Korean, Chinese, Arabic, Hindi
- And 100+ more via Whisper multilingual model

### Translation Support
- All languages supported by TranslateGemma (100+)
- Common pairs: Urdu â†” English, French, Spanish, German, etc.

### TTS Support
- English (US/UK), French, Spanish, German, Italian, Portuguese
- Japanese, Korean, Chinese, Arabic, Hindi
- And more via Piper voice models

## ğŸ“ Project Structure

```
Text_to_Speech/
â”œâ”€â”€ api_server.py              # FastAPI backend server
â”œâ”€â”€ speech_to_text.py          # Urdu transcription (fine-tuned model)
â”œâ”€â”€ speech_to_text_multi.py    # Multi-language transcription
â”œâ”€â”€ translate_text.py           # Urdu â†’ Target translation
â”œâ”€â”€ translate_text_multi.py     # Bidirectional translation
â”œâ”€â”€ text_to_speech.py          # Piper TTS integration
â”œâ”€â”€ ollama_integration.py      # Ollama client wrapper
â”œâ”€â”€ language_codes.py          # Language code mappings
â”œâ”€â”€ text_cleaner.py            # Text cleaning utilities
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ start_ui.sh                # Startup script
â”œâ”€â”€ frontend/                  # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx            # Main React component
â”‚   â”‚   â”œâ”€â”€ App.css            # Styles
â”‚   â”‚   â”œâ”€â”€ main.jsx           # Entry point
â”‚   â”‚   â””â”€â”€ index.css          # Global styles
â”‚   â”œâ”€â”€ package.json           # Frontend dependencies
â”‚   â””â”€â”€ vite.config.js         # Vite configuration
â””â”€â”€ screenshots/               # UI screenshots
    â””â”€â”€ README.md              # Screenshot instructions
```

## ğŸ¯ What's Been Accomplished

### Phase 1: Core Translation Pipeline
- âœ… Implemented Urdu speech-to-text using fine-tuned Whisper model
- âœ… Integrated TranslateGemma for high-quality translation
- âœ… Added Piper TTS for natural-sounding speech synthesis
- âœ… Created complete pipeline: Record â†’ Transcribe â†’ Translate â†’ TTS â†’ Play

### Phase 2: Modern Web UI
- âœ… Built React frontend with Vite
- âœ… Implemented browser-based audio recording
- âœ… Created modern, responsive UI design
- âœ… Added real-time status updates and progress indicators
- âœ… Integrated audio playback functionality

### Phase 3: Two-Way Translation
- âœ… Implemented bidirectional translation support
- âœ… Created conversation mode with speaker switching
- âœ… Added conversation history tracking
- âœ… Built multi-language transcription support
- âœ… Added automatic turn-taking indicators

### Phase 4: API & Integration
- âœ… Created FastAPI backend with REST endpoints
- âœ… Implemented CORS for frontend-backend communication
- âœ… Added base64 audio handling for browser compatibility
- âœ… Created comprehensive error handling

### Key Achievements
- ğŸ¯ **100+ Language Support**: Translate between any supported language pairs
- âš¡ **Fast Processing**: GPU-accelerated transcription on Apple Silicon
- ğŸ¨ **Modern UX**: Clean, intuitive interface with real-time feedback
- ğŸ”„ **Bidirectional**: Full conversation support, not just one-way translation
- ğŸ“± **Responsive**: Works on desktop and mobile devices

## ğŸ“„ License

MIT License - feel free to use this project for your own purposes.

## ğŸ™ Acknowledgments

- **Whisper**: OpenAI's speech recognition model
- **TranslateGemma**: Translation model via Ollama
- **Piper TTS**: Fast, local text-to-speech
- **Fine-tuned Urdu Model**: `khawajaaliarshad/whisper-small-urdu`

## ğŸ“§ Contact

For questions or issues, please open an issue on the repository, or contact me via
Email: mortazaameer8@gmail.com
Website: Mortaza76.github.io

Muhammad Ameer Mortaza
Ghulam Ishaq Khan Institute (GIKI)
